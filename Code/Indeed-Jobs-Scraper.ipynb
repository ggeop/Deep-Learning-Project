{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from html2text import html2text\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job Title Function\n",
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "        for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job URL Function\n",
    "def extract_job_url_from_result(soup): \n",
    "    urls = []\n",
    "    for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "        for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "            this_url = a['href']\n",
    "            to_go_url = \"https://www.indeed.com/viewjob\" + this_url[7:]\n",
    "            urls.append(to_go_url)\n",
    "    return(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_jobURL(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    table = soup.find('table', id = 'job-content')\n",
    "    span = table.find('span', id = 'job_summary')\n",
    "    div = span.find('div')\n",
    "    \n",
    "    return(html2text(str(div)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job Description\n",
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll(\"span\", attrs = {\"class\": \"summary\"})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Job Title Dataset\n",
    "job_titles=pd.read_csv(\"..\\Datasets\\Job_Titles.csv\", sep = \",\")\n",
    "\n",
    "#Create job_titles list\n",
    "job_list=list(job_titles.Job_titles)\n",
    "\n",
    "#Replace spaces with '+'\n",
    "job_list2=[]\n",
    "for item in job_list:\n",
    "    job_list2.append(item.replace(' ', '+'))\n",
    "    \n",
    "job_list=job_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Entry Operator',\n",
      " 'Data Analyst',\n",
      " 'Internship: Child Poverty on Violence against Children, Data & Analytic '\n",
      " 'Section, DRP – NYHQ, Requisition #513831',\n",
      " 'SMS/SRC Data Analyst',\n",
      " 'DATA ANALYST',\n",
      " 'HBO Communications Assistant',\n",
      " 'Data Entry Operator',\n",
      " 'Intern: Investment Data Scientist',\n",
      " 'Data Analyst, Asc',\n",
      " 'Data Entry']\n",
      "['The role involves collecting and entering data pertaining to land and '\n",
      " 'property sales deeds as well as DLD documentations....',\n",
      " 'The Data Analyst will support project development and decision-making by '\n",
      " 'managing, analyzing, and reporting data....',\n",
      " 'The purpose of the Internship is to support data and statistics work on '\n",
      " 'Child Poverty on Violence against Children including updating the global '\n",
      " 'databases,...',\n",
      " 'Provide technical expertise to the Manager, SRC Data Analysis regarding data '\n",
      " 'models, database design development, and data mining....',\n",
      " 'Responsible for setting up data pulls from multiple touch points into a '\n",
      " 'database (using API calls to 3rd party data) for both historic storage and '\n",
      " 'data...',\n",
      " 'Familiarity with various social media platforms and an interest in '\n",
      " 'analyzing/organizing/interpreting data. The Communications Assistant reports '\n",
      " 'to the Media...',\n",
      " 'Performs clerical and support activities necessary to assist in laboratory '\n",
      " 'operations and all areas of specimen receipt and registration. Serves as '\n",
      " 'a...',\n",
      " 'Participate in meetings with data vendors to evaluate new data sources. '\n",
      " 'Duties include leveraging alternative data (e.g....',\n",
      " 'Effective communication and data presentation skills are required. '\n",
      " 'Proficiency in MATLAB/Python/LabVIEW programming with an ability to adapt '\n",
      " 'and learn other...',\n",
      " 'Data Entry experience. - Ensures accuracy and completeness data. Medical '\n",
      " 'Data Entry knowledge is a plus. - Performs clerical tasks in the data entry '\n",
      " 'function....']\n"
     ]
    }
   ],
   "source": [
    "#Testing the above code\n",
    "URL =\"https://www.indeed.com/jobs?q=data%2420%2C000&l=+New+York&start=10\"\n",
    "    \n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "\n",
    "#specifying a desired format of “page” using the html parser\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "pp.pprint(extract_job_title_from_result(soup))\n",
    "\n",
    "pp.pprint(extract_summary_from_result(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/viewjob?jk=49bc5a364095bb87&fccid=52df7d9b7f5fccc3&vjs=3\n",
      "\n",
      "This is three month temp contract role for bilingual candidates else\n",
      "candidates who could read and type , would be considered. The role involves\n",
      "collecting and entering data pertaining to land and property sales deeds as\n",
      "well as DLD documentations. You will also maintain incident report, update all\n",
      "database Keep information confidential, store completed work in designated\n",
      "location.  \n",
      "**Salary**  \n",
      "**** 5000 per month inclusive of fixed allowances.  \n",
      "**Requirements**  \n",
      "****\n",
      "\n",
      "  * High School or University Graduates with 2-4 years similar experience.\n",
      "  * Good communication skills and a great attitude.\n",
      "  * Essential skills: Excellent typing skills (Basic knowledge about database software is plus) MS Excel, MS Word, MS Power point (Arabic and English).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_list = extract_job_url_from_result(soup)\n",
    "\n",
    "print(url_list[0])\n",
    "print()\n",
    "print(extract_text_from_jobURL(url_list[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
