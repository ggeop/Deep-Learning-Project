{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job Title Function\n",
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "        for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job URL Function\n",
    "def extract_job_url_from_result(soup): \n",
    "    urls = []\n",
    "    for div in soup.find_all(name = \"div\", attrs = {\"class\":\"row\"}):\n",
    "        for a in div.find_all(name = \"a\", attrs = {\"data-tn-element\":\"jobTitle\"}):\n",
    "            this_url = a['href']\n",
    "            to_go_url = \"https://www.indeed.com/viewjob\" + this_url[7:]\n",
    "            urls.append(to_go_url)\n",
    "    return(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Job Description\n",
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    spans = soup.findAll(\"span\", attrs = {\"class\": \"summary\"})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Job Title Dataset\n",
    "job_titles=pd.read_csv(\"..\\Datasets\\Job_Titles.csv\", sep = \",\")\n",
    "\n",
    "#Create job_titles list\n",
    "job_list=list(job_titles.Job_titles)\n",
    "\n",
    "#Replace spaces with '+'\n",
    "job_list2=[]\n",
    "for item in job_list:\n",
    "    job_list2.append(item.replace(' ', '+'))\n",
    "    \n",
    "job_list=job_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Internship: Child Poverty on Violence against Children, Data & Analytic '\n",
      " 'Section, DRP – NYHQ, Requisition #513831',\n",
      " 'Data Analyst',\n",
      " 'Research Associate - Data Collection',\n",
      " 'Data Entry',\n",
      " 'HBO Communications Assistant',\n",
      " 'Junior Data Analyst',\n",
      " 'CLERK, DATA ENTRY (FULL-TIME) - Summer opportunity',\n",
      " 'Data Quality Analyst - Computers/Home Theater',\n",
      " 'SMS/SRC Data Analyst',\n",
      " 'Intern: Investment Data Scientist']\n",
      "['https://www.indeed.com/viewjob?jk=258a27b99809a3c4&fccid=b829ee9b3a982489&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=7de787dd7ed318ab&fccid=667ba717ce627077&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=9e55238113cf74a8&fccid=5202200066edf11e&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=5aaec5a7e826bb6d&fccid=88f5eba43de70e76&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=5db3d9169c925911&fccid=3e3eaa6aedf690a3&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=4c6f20c4eac41d6b&fccid=e1372f0c6aadd565&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=30301460376201ec&fccid=c55f4ad42cee2cd3&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=47b9d2df4e223585&fccid=cb7ece531bc74ee6&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=37983718d10eabe9&fccid=8d1f0c6fbf5b4c47&vjs=3',\n",
      " 'https://www.indeed.com/viewjob?jk=305410d11dac42d9&fccid=29a5d99712fe1c7e&vjs=3']\n",
      "['The purpose of the Internship is to support data and statistics work on '\n",
      " 'Child Poverty on Violence against Children including updating the global '\n",
      " 'databases,...',\n",
      " 'The Data Analyst will support project development and decision-making by '\n",
      " 'managing, analyzing, and reporting data....',\n",
      " 'Reconciling data discrepancies and inconsistencies. Validating information '\n",
      " 'by cross-referencing data on multiple sources....',\n",
      " 'Data Entry experience. - Ensures accuracy and completeness data. Medical '\n",
      " 'Data Entry knowledge is a plus. - Performs clerical tasks in the data entry '\n",
      " 'function....',\n",
      " 'Familiarity with various social media platforms and an interest in '\n",
      " 'analyzing/organizing/interpreting data. The Communications Assistant reports '\n",
      " 'to the Media...',\n",
      " 'Coordinate and collect input data from different departments, check data '\n",
      " 'integrity, summarize and analyze data to communicate output to senior '\n",
      " 'management....',\n",
      " 'We have an opening for a full-time CLERK, DATA ENTRY position. Fills in for '\n",
      " 'other Data Entry Clerks as needed and works cooperatively with others....',\n",
      " 'They ensure that product data becomes and remains clean and accurate. The '\n",
      " 'Data Quality Analyst is responsible for structuring and management of '\n",
      " 'product...',\n",
      " 'Provide technical expertise to the Manager, SRC Data Analysis regarding data '\n",
      " 'models, database design development, and data mining....',\n",
      " 'Participate in meetings with data vendors to evaluate new data sources. '\n",
      " 'Duties include leveraging alternative data (e.g....']\n"
     ]
    }
   ],
   "source": [
    "#Testing the above code\n",
    "URL =\"https://www.indeed.com/jobs?q=data%2420%2C000&l=+New+York&start=10\"\n",
    "    \n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "\n",
    "#specifying a desired format of “page” using the html parser\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "pp.pprint(extract_job_title_from_result(soup))\n",
    "\n",
    "pp.pprint(extract_job_url_from_result(soup))\n",
    "\n",
    "pp.pprint(extract_summary_from_result(soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
